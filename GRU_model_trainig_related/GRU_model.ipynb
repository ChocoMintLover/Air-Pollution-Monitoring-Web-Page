{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout, BatchNormalization, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days to refer to train\n",
    "WINDOW_SIZE = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['aqi', 'co', 'no', 'no2', 'o3', 'so2', 'pm2_5', 'pm10', 'nh3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size - 7 + 1):  # predict 7 days\n",
    "        X.append(data[i:i+window_size])         \n",
    "        y.append(data[i+window_size:i+window_size+7]) \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(64, activation='tanh', return_sequences=True, input_shape=(WINDOW_SIZE, len(features))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(GRU(32, activation='tanh', return_sequences=True))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(7 * len(features)))\n",
    "model.add(Reshape((7, len(features))))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12844\\3470139634.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\minja\\anaconda3\\envs\\tf210\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     \"\"\"\n\u001b[0;32m   1345\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1346\u001b[1;33m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[0;32m   1347\u001b[0m                        \u001b[1;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1348\u001b[0m                        \u001b[1;34m'`fit()` with some data, or specify '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model learned 3 years of data in busan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: X=(4360, 30, 9), y=(4360, 7, 9)\n",
      "Test shape: X=(4355, 30, 9), y=(4355, 7, 9)\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12844\\1133579533.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m# 모델 학습\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     model.fit(X_train, y_train, validation_data=(X_test, y_test), \n\u001b[1;32m---> 33\u001b[1;33m                                epochs=20, batch_size=32, callbacks=[early_stopping])\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\minja\\anaconda3\\envs\\tf210\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\minja\\anaconda3\\envs\\tf210\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\minja\\anaconda3\\envs\\tf210\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\minja\\anaconda3\\envs\\tf210\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "busan_df = pd.read_csv('./pollution_data/baseline_data/Busan_pollution_data_3_years.csv')\n",
    "busan_df = busan_df[features]\n",
    "data_array = busan_df.to_numpy()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data_array)\n",
    "\n",
    "X, y = create_sequences(data_scaled, WINDOW_SIZE)\n",
    "\n",
    "histories = []\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    print(f\"Train shape: X={X_train.shape}, y={y_train.shape}\")\n",
    "    print(f\"Test shape: X={X_test.shape}, y={y_test.shape}\")\n",
    "\n",
    "    histories.append(model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20,\n",
    "              batch_size=32, callbacks=[early_stopping]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('./models/mj_pretrained_baseline_model_GRU_capable.keras')\n",
    "model.save('./models/mj_pretrained_baseline_model_GRU_capable.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x206a4278190>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = []\n",
    "for history in histories:\n",
    "    losses.append(history.history['val_loss'][0])\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원래의 scale로 바꾸기 위하여 받아온 데이터의 평균을 이 값에 곱해서 사용하면 될듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x206a3015d20>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(model.predict(X[4390:4420])[-1])\n",
    "plt.legend(features, loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuning with other cities's dataset for 1 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "datasets = glob('./pollution_data/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: California_pollution_data.csv\n",
      "Epoch 1/20\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0119 - mae: 0.0708 - val_loss: 0.0102 - val_mae: 0.0671\n",
      "Epoch 2/20\n",
      "47/47 [==============================] - 1s 26ms/step - loss: 0.0088 - mae: 0.0603 - val_loss: 0.0083 - val_mae: 0.0588\n",
      "Epoch 3/20\n",
      "47/47 [==============================] - 1s 24ms/step - loss: 0.0082 - mae: 0.0583 - val_loss: 0.0076 - val_mae: 0.0538\n",
      "Epoch 4/20\n",
      "47/47 [==============================] - 1s 25ms/step - loss: 0.0076 - mae: 0.0560 - val_loss: 0.0078 - val_mae: 0.0544\n",
      "Epoch 5/20\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0073 - mae: 0.0549 - val_loss: 0.0113 - val_mae: 0.0711\n",
      "Epoch 6/20\n",
      "47/47 [==============================] - 1s 25ms/step - loss: 0.0072 - mae: 0.0546 - val_loss: 0.0081 - val_mae: 0.0567\n",
      "Epoch 7/20\n",
      "47/47 [==============================] - 1s 25ms/step - loss: 0.0070 - mae: 0.0538 - val_loss: 0.0075 - val_mae: 0.0539\n",
      "Epoch 8/20\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.0066 - mae: 0.0525 - val_loss: 0.0077 - val_mae: 0.0546\n",
      "Epoch 9/20\n",
      "47/47 [==============================] - 1s 25ms/step - loss: 0.0066 - mae: 0.0523 - val_loss: 0.0075 - val_mae: 0.0538\n",
      "Epoch 10/20\n",
      "47/47 [==============================] - 1s 25ms/step - loss: 0.0063 - mae: 0.0512 - val_loss: 0.0074 - val_mae: 0.0521\n",
      "Epoch 11/20\n",
      "47/47 [==============================] - 1s 25ms/step - loss: 0.0063 - mae: 0.0511 - val_loss: 0.0083 - val_mae: 0.0579\n",
      "Epoch 12/20\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.0062 - mae: 0.0510 - val_loss: 0.0081 - val_mae: 0.0574\n",
      "Epoch 13/20\n",
      "47/47 [==============================] - 1s 26ms/step - loss: 0.0061 - mae: 0.0504 - val_loss: 0.0089 - val_mae: 0.0610\n",
      "Epoch 14/20\n",
      "47/47 [==============================] - 1s 25ms/step - loss: 0.0060 - mae: 0.0501 - val_loss: 0.0083 - val_mae: 0.0581\n",
      "Epoch 15/20\n",
      "47/47 [==============================] - 1s 24ms/step - loss: 0.0058 - mae: 0.0494 - val_loss: 0.0081 - val_mae: 0.0570\n",
      "Epoch 1/20\n",
      "93/93 [==============================] - 2s 22ms/step - loss: 0.0068 - mae: 0.0514 - val_loss: 0.0073 - val_mae: 0.0510\n",
      "Epoch 2/20\n",
      "93/93 [==============================] - 2s 22ms/step - loss: 0.0064 - mae: 0.0497 - val_loss: 0.0071 - val_mae: 0.0500\n",
      "Epoch 3/20\n",
      "93/93 [==============================] - 2s 22ms/step - loss: 0.0062 - mae: 0.0489 - val_loss: 0.0079 - val_mae: 0.0528\n",
      "Epoch 4/20\n",
      "93/93 [==============================] - 2s 21ms/step - loss: 0.0061 - mae: 0.0487 - val_loss: 0.0077 - val_mae: 0.0517\n",
      "Epoch 5/20\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 0.0060 - mae: 0.0478 - val_loss: 0.0073 - val_mae: 0.0508\n",
      "Epoch 6/20\n",
      "93/93 [==============================] - 2s 22ms/step - loss: 0.0059 - mae: 0.0475 - val_loss: 0.0078 - val_mae: 0.0522\n",
      "Epoch 7/20\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.0058 - mae: 0.0473 - val_loss: 0.0082 - val_mae: 0.0544\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 3s 22ms/step - loss: 0.0064 - mae: 0.0489 - val_loss: 0.0052 - val_mae: 0.0414\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.0061 - mae: 0.0480 - val_loss: 0.0053 - val_mae: 0.0418\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 22ms/step - loss: 0.0059 - mae: 0.0470 - val_loss: 0.0059 - val_mae: 0.0432\n",
      "Epoch 4/20\n",
      "139/139 [==============================] - 3s 21ms/step - loss: 0.0058 - mae: 0.0464 - val_loss: 0.0051 - val_mae: 0.0404\n",
      "Epoch 5/20\n",
      "139/139 [==============================] - 3s 21ms/step - loss: 0.0057 - mae: 0.0460 - val_loss: 0.0050 - val_mae: 0.0388\n",
      "Epoch 6/20\n",
      "139/139 [==============================] - 3s 21ms/step - loss: 0.0055 - mae: 0.0454 - val_loss: 0.0051 - val_mae: 0.0397\n",
      "Epoch 7/20\n",
      "139/139 [==============================] - 3s 21ms/step - loss: 0.0054 - mae: 0.0449 - val_loss: 0.0059 - val_mae: 0.0434\n",
      "Epoch 8/20\n",
      "139/139 [==============================] - 3s 23ms/step - loss: 0.0054 - mae: 0.0449 - val_loss: 0.0051 - val_mae: 0.0396\n",
      "Epoch 9/20\n",
      "139/139 [==============================] - 3s 22ms/step - loss: 0.0054 - mae: 0.0447 - val_loss: 0.0054 - val_mae: 0.0413\n",
      "Epoch 10/20\n",
      "139/139 [==============================] - 3s 22ms/step - loss: 0.0052 - mae: 0.0441 - val_loss: 0.0057 - val_mae: 0.0431\n",
      "Epoch 1/20\n",
      "185/185 [==============================] - 4s 21ms/step - loss: 0.0054 - mae: 0.0438 - val_loss: 0.0054 - val_mae: 0.0449\n",
      "Epoch 2/20\n",
      "185/185 [==============================] - 4s 21ms/step - loss: 0.0053 - mae: 0.0433 - val_loss: 0.0056 - val_mae: 0.0481\n",
      "Epoch 3/20\n",
      "185/185 [==============================] - 4s 21ms/step - loss: 0.0051 - mae: 0.0429 - val_loss: 0.0052 - val_mae: 0.0426\n",
      "Epoch 4/20\n",
      "185/185 [==============================] - 4s 21ms/step - loss: 0.0050 - mae: 0.0424 - val_loss: 0.0054 - val_mae: 0.0443\n",
      "Epoch 5/20\n",
      "185/185 [==============================] - 4s 21ms/step - loss: 0.0050 - mae: 0.0423 - val_loss: 0.0054 - val_mae: 0.0441\n",
      "Epoch 6/20\n",
      "185/185 [==============================] - 4s 21ms/step - loss: 0.0049 - mae: 0.0421 - val_loss: 0.0052 - val_mae: 0.0433\n",
      "Epoch 7/20\n",
      "185/185 [==============================] - 4s 21ms/step - loss: 0.0048 - mae: 0.0417 - val_loss: 0.0059 - val_mae: 0.0461\n",
      "Epoch 8/20\n",
      "185/185 [==============================] - 4s 21ms/step - loss: 0.0048 - mae: 0.0415 - val_loss: 0.0054 - val_mae: 0.0442\n",
      "Epoch 9/20\n",
      "185/185 [==============================] - 4s 21ms/step - loss: 0.0047 - mae: 0.0415 - val_loss: 0.0054 - val_mae: 0.0436\n",
      "Epoch 10/20\n",
      "185/185 [==============================] - 4s 21ms/step - loss: 0.0046 - mae: 0.0411 - val_loss: 0.0055 - val_mae: 0.0444\n",
      "Epoch 11/20\n",
      "185/185 [==============================] - 4s 21ms/step - loss: 0.0046 - mae: 0.0409 - val_loss: 0.0058 - val_mae: 0.0453\n",
      "Epoch 1/20\n",
      "231/231 [==============================] - 5s 21ms/step - loss: 0.0049 - mae: 0.0421 - val_loss: 0.0067 - val_mae: 0.0536\n",
      "Epoch 2/20\n",
      "231/231 [==============================] - 5s 21ms/step - loss: 0.0049 - mae: 0.0419 - val_loss: 0.0068 - val_mae: 0.0529\n",
      "Epoch 3/20\n",
      "231/231 [==============================] - 5s 21ms/step - loss: 0.0048 - mae: 0.0415 - val_loss: 0.0061 - val_mae: 0.0477\n",
      "Epoch 4/20\n",
      "231/231 [==============================] - 5s 21ms/step - loss: 0.0047 - mae: 0.0410 - val_loss: 0.0069 - val_mae: 0.0513\n",
      "Epoch 5/20\n",
      "231/231 [==============================] - 5s 21ms/step - loss: 0.0047 - mae: 0.0410 - val_loss: 0.0063 - val_mae: 0.0489\n",
      "Epoch 6/20\n",
      "231/231 [==============================] - 5s 21ms/step - loss: 0.0046 - mae: 0.0406 - val_loss: 0.0065 - val_mae: 0.0509\n",
      "Epoch 7/20\n",
      "231/231 [==============================] - 5s 21ms/step - loss: 0.0046 - mae: 0.0404 - val_loss: 0.0069 - val_mae: 0.0532\n",
      "Epoch 8/20\n",
      "231/231 [==============================] - 5s 21ms/step - loss: 0.0045 - mae: 0.0402 - val_loss: 0.0066 - val_mae: 0.0500\n",
      "Dataset: London_pollution_data.csv\n",
      "Epoch 1/20\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.0074 - mae: 0.0519 - val_loss: 0.0062 - val_mae: 0.0522\n",
      "Epoch 2/20\n",
      "47/47 [==============================] - 1s 29ms/step - loss: 0.0059 - mae: 0.0469 - val_loss: 0.0052 - val_mae: 0.0454\n",
      "Epoch 3/20\n",
      "47/47 [==============================] - 1s 25ms/step - loss: 0.0051 - mae: 0.0437 - val_loss: 0.0049 - val_mae: 0.0450\n",
      "Epoch 4/20\n",
      "47/47 [==============================] - 1s 25ms/step - loss: 0.0049 - mae: 0.0431 - val_loss: 0.0045 - val_mae: 0.0416\n",
      "Epoch 5/20\n",
      "47/47 [==============================] - 1s 26ms/step - loss: 0.0047 - mae: 0.0424 - val_loss: 0.0046 - val_mae: 0.0433\n",
      "Epoch 6/20\n",
      "47/47 [==============================] - 1s 25ms/step - loss: 0.0044 - mae: 0.0411 - val_loss: 0.0047 - val_mae: 0.0416\n",
      "Epoch 7/20\n",
      "47/47 [==============================] - 1s 24ms/step - loss: 0.0045 - mae: 0.0417 - val_loss: 0.0047 - val_mae: 0.0420\n",
      "Epoch 8/20\n",
      "47/47 [==============================] - 1s 26ms/step - loss: 0.0040 - mae: 0.0403 - val_loss: 0.0049 - val_mae: 0.0437\n",
      "Epoch 9/20\n",
      "47/47 [==============================] - 1s 25ms/step - loss: 0.0041 - mae: 0.0401 - val_loss: 0.0044 - val_mae: 0.0400\n",
      "Epoch 10/20\n",
      "47/47 [==============================] - 1s 25ms/step - loss: 0.0038 - mae: 0.0385 - val_loss: 0.0046 - val_mae: 0.0413\n",
      "Epoch 11/20\n",
      "47/47 [==============================] - 1s 25ms/step - loss: 0.0040 - mae: 0.0403 - val_loss: 0.0051 - val_mae: 0.0433\n",
      "Epoch 12/20\n",
      "47/47 [==============================] - 1s 26ms/step - loss: 0.0036 - mae: 0.0380 - val_loss: 0.0048 - val_mae: 0.0426\n",
      "Epoch 13/20\n",
      "47/47 [==============================] - 1s 26ms/step - loss: 0.0036 - mae: 0.0376 - val_loss: 0.0047 - val_mae: 0.0413\n",
      "Epoch 14/20\n",
      "47/47 [==============================] - 1s 26ms/step - loss: 0.0036 - mae: 0.0380 - val_loss: 0.0047 - val_mae: 0.0408\n",
      "Epoch 1/20\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 0.0041 - mae: 0.0396 - val_loss: 0.0034 - val_mae: 0.0325\n",
      "Epoch 2/20\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 0.0039 - mae: 0.0387 - val_loss: 0.0035 - val_mae: 0.0321\n",
      "Epoch 3/20\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 0.0039 - mae: 0.0386 - val_loss: 0.0033 - val_mae: 0.0328\n",
      "Epoch 4/20\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 0.0038 - mae: 0.0381 - val_loss: 0.0033 - val_mae: 0.0316\n",
      "Epoch 5/20\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 0.0036 - mae: 0.0372 - val_loss: 0.0032 - val_mae: 0.0320\n",
      "Epoch 6/20\n",
      "93/93 [==============================] - 2s 22ms/step - loss: 0.0037 - mae: 0.0372 - val_loss: 0.0031 - val_mae: 0.0312\n",
      "Epoch 7/20\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 0.0035 - mae: 0.0367 - val_loss: 0.0031 - val_mae: 0.0315\n",
      "Epoch 8/20\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 0.0035 - mae: 0.0366 - val_loss: 0.0032 - val_mae: 0.0309\n",
      "Epoch 9/20\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 0.0035 - mae: 0.0367 - val_loss: 0.0032 - val_mae: 0.0304\n",
      "Epoch 10/20\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 0.0034 - mae: 0.0362 - val_loss: 0.0033 - val_mae: 0.0325\n",
      "Epoch 11/20\n",
      "93/93 [==============================] - 2s 22ms/step - loss: 0.0033 - mae: 0.0355 - val_loss: 0.0032 - val_mae: 0.0312\n",
      "Epoch 1/20\n",
      "139/139 [==============================] - 3s 22ms/step - loss: 0.0034 - mae: 0.0348 - val_loss: 0.0025 - val_mae: 0.0290\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 3s 22ms/step - loss: 0.0032 - mae: 0.0339 - val_loss: 0.0026 - val_mae: 0.0296\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 3s 21ms/step - loss: 0.0031 - mae: 0.0336 - val_loss: 0.0027 - val_mae: 0.0324\n",
      "Epoch 4/20\n",
      "139/139 [==============================] - 3s 21ms/step - loss: 0.0031 - mae: 0.0334 - val_loss: 0.0028 - val_mae: 0.0300\n",
      "Epoch 5/20\n",
      "139/139 [==============================] - 3s 21ms/step - loss: 0.0030 - mae: 0.0327 - val_loss: 0.0027 - val_mae: 0.0304\n",
      "Epoch 6/20\n",
      "139/139 [==============================] - 3s 22ms/step - loss: 0.0031 - mae: 0.0330 - val_loss: 0.0025 - val_mae: 0.0293\n",
      "Epoch 7/20\n",
      "139/139 [==============================] - 3s 22ms/step - loss: 0.0030 - mae: 0.0329 - val_loss: 0.0028 - val_mae: 0.0305\n",
      "Epoch 8/20\n",
      "139/139 [==============================] - 3s 21ms/step - loss: 0.0029 - mae: 0.0323 - val_loss: 0.0026 - val_mae: 0.0297\n",
      "Epoch 9/20\n",
      "139/139 [==============================] - 3s 21ms/step - loss: 0.0029 - mae: 0.0325 - val_loss: 0.0029 - val_mae: 0.0324\n",
      "Epoch 10/20\n",
      "139/139 [==============================] - 3s 21ms/step - loss: 0.0029 - mae: 0.0322 - val_loss: 0.0024 - val_mae: 0.0271\n",
      "Epoch 11/20\n",
      "139/139 [==============================] - 3s 21ms/step - loss: 0.0028 - mae: 0.0321 - val_loss: 0.0027 - val_mae: 0.0293\n",
      "Epoch 12/20\n",
      "139/139 [==============================] - 3s 21ms/step - loss: 0.0027 - mae: 0.0315 - val_loss: 0.0024 - val_mae: 0.0278\n",
      "Epoch 13/20\n",
      "139/139 [==============================] - 3s 21ms/step - loss: 0.0028 - mae: 0.0316 - val_loss: 0.0026 - val_mae: 0.0289\n",
      "Epoch 14/20\n",
      "139/139 [==============================] - 3s 21ms/step - loss: 0.0027 - mae: 0.0316 - val_loss: 0.0025 - val_mae: 0.0289\n",
      "Epoch 15/20\n",
      "139/139 [==============================] - 3s 21ms/step - loss: 0.0027 - mae: 0.0312 - val_loss: 0.0026 - val_mae: 0.0281\n",
      "Epoch 1/20\n",
      "185/185 [==============================] - 4s 20ms/step - loss: 0.0027 - mae: 0.0306 - val_loss: 0.0057 - val_mae: 0.0466\n",
      "Epoch 2/20\n",
      "185/185 [==============================] - 4s 22ms/step - loss: 0.0026 - mae: 0.0305 - val_loss: 0.0053 - val_mae: 0.0437\n",
      "Epoch 3/20\n",
      "185/185 [==============================] - 4s 21ms/step - loss: 0.0026 - mae: 0.0305 - val_loss: 0.0055 - val_mae: 0.0465\n",
      "Epoch 4/20\n",
      "185/185 [==============================] - 4s 21ms/step - loss: 0.0026 - mae: 0.0302 - val_loss: 0.0051 - val_mae: 0.0426\n",
      "Epoch 5/20\n",
      "185/185 [==============================] - 4s 21ms/step - loss: 0.0026 - mae: 0.0303 - val_loss: 0.0058 - val_mae: 0.0468\n",
      "Epoch 6/20\n",
      "185/185 [==============================] - 4s 21ms/step - loss: 0.0025 - mae: 0.0299 - val_loss: 0.0052 - val_mae: 0.0438\n",
      "Epoch 7/20\n",
      "185/185 [==============================] - 4s 22ms/step - loss: 0.0025 - mae: 0.0300 - val_loss: 0.0051 - val_mae: 0.0423\n",
      "Epoch 8/20\n",
      "185/185 [==============================] - 4s 21ms/step - loss: 0.0025 - mae: 0.0298 - val_loss: 0.0053 - val_mae: 0.0445\n",
      "Epoch 9/20\n",
      "185/185 [==============================] - 4s 21ms/step - loss: 0.0025 - mae: 0.0297 - val_loss: 0.0052 - val_mae: 0.0415\n",
      "Epoch 1/20\n",
      "231/231 [==============================] - 5s 21ms/step - loss: 0.0030 - mae: 0.0323 - val_loss: 0.0034 - val_mae: 0.0345\n",
      "Epoch 2/20\n",
      "231/231 [==============================] - 5s 20ms/step - loss: 0.0029 - mae: 0.0323 - val_loss: 0.0038 - val_mae: 0.0372\n",
      "Epoch 3/20\n",
      "231/231 [==============================] - 5s 21ms/step - loss: 0.0028 - mae: 0.0315 - val_loss: 0.0037 - val_mae: 0.0378\n",
      "Epoch 4/20\n",
      "231/231 [==============================] - 5s 21ms/step - loss: 0.0028 - mae: 0.0313 - val_loss: 0.0033 - val_mae: 0.0351\n",
      "Epoch 5/20\n",
      "231/231 [==============================] - 5s 20ms/step - loss: 0.0028 - mae: 0.0311 - val_loss: 0.0034 - val_mae: 0.0344\n",
      "Epoch 6/20\n",
      "231/231 [==============================] - 5s 21ms/step - loss: 0.0027 - mae: 0.0310 - val_loss: 0.0034 - val_mae: 0.0317\n",
      "Epoch 7/20\n",
      "231/231 [==============================] - 5s 22ms/step - loss: 0.0026 - mae: 0.0307 - val_loss: 0.0037 - val_mae: 0.0366\n",
      "Epoch 8/20\n",
      "231/231 [==============================] - 5s 21ms/step - loss: 0.0026 - mae: 0.0306 - val_loss: 0.0036 - val_mae: 0.0367\n",
      "Epoch 9/20\n",
      "231/231 [==============================] - 5s 20ms/step - loss: 0.0026 - mae: 0.0306 - val_loss: 0.0032 - val_mae: 0.0319\n",
      "Epoch 10/20\n",
      "231/231 [==============================] - 5s 20ms/step - loss: 0.0026 - mae: 0.0304 - val_loss: 0.0033 - val_mae: 0.0323\n",
      "Epoch 11/20\n",
      "231/231 [==============================] - 5s 21ms/step - loss: 0.0026 - mae: 0.0304 - val_loss: 0.0034 - val_mae: 0.0359\n",
      "Epoch 12/20\n",
      "231/231 [==============================] - 5s 20ms/step - loss: 0.0026 - mae: 0.0301 - val_loss: 0.0035 - val_mae: 0.0328\n",
      "Epoch 13/20\n",
      "231/231 [==============================] - 5s 20ms/step - loss: 0.0026 - mae: 0.0302 - val_loss: 0.0034 - val_mae: 0.0343\n",
      "Epoch 14/20\n",
      "231/231 [==============================] - 5s 21ms/step - loss: 0.0025 - mae: 0.0298 - val_loss: 0.0035 - val_mae: 0.0331\n",
      "Dataset: New_Delhi_pollution_data.csv\n",
      "Epoch 1/20\n",
      "46/46 [==============================] - 1s 27ms/step - loss: 0.0133 - mae: 0.0731 - val_loss: 0.0134 - val_mae: 0.0844\n",
      "Epoch 2/20\n",
      "46/46 [==============================] - 1s 27ms/step - loss: 0.0080 - mae: 0.0582 - val_loss: 0.0098 - val_mae: 0.0616\n",
      "Epoch 3/20\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.0071 - mae: 0.0534 - val_loss: 0.0097 - val_mae: 0.0638\n",
      "Epoch 4/20\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.0061 - mae: 0.0495 - val_loss: 0.0089 - val_mae: 0.0610\n",
      "Epoch 5/20\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.0063 - mae: 0.0510 - val_loss: 0.0093 - val_mae: 0.0618\n",
      "Epoch 6/20\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.0056 - mae: 0.0480 - val_loss: 0.0090 - val_mae: 0.0627\n",
      "Epoch 7/20\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.0053 - mae: 0.0459 - val_loss: 0.0087 - val_mae: 0.0588\n",
      "Epoch 8/20\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.0051 - mae: 0.0454 - val_loss: 0.0098 - val_mae: 0.0651\n",
      "Epoch 9/20\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.0050 - mae: 0.0453 - val_loss: 0.0088 - val_mae: 0.0589\n",
      "Epoch 10/20\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.0048 - mae: 0.0440 - val_loss: 0.0090 - val_mae: 0.0633\n",
      "Epoch 11/20\n",
      "46/46 [==============================] - 1s 27ms/step - loss: 0.0047 - mae: 0.0434 - val_loss: 0.0096 - val_mae: 0.0650\n",
      "Epoch 12/20\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.0045 - mae: 0.0431 - val_loss: 0.0094 - val_mae: 0.0635\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.0068 - mae: 0.0525 - val_loss: 0.0084 - val_mae: 0.0571\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.0061 - mae: 0.0499 - val_loss: 0.0090 - val_mae: 0.0596\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.0058 - mae: 0.0489 - val_loss: 0.0081 - val_mae: 0.0543\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.0057 - mae: 0.0484 - val_loss: 0.0084 - val_mae: 0.0549\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.0054 - mae: 0.0473 - val_loss: 0.0085 - val_mae: 0.0538\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.0053 - mae: 0.0465 - val_loss: 0.0088 - val_mae: 0.0576\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.0052 - mae: 0.0464 - val_loss: 0.0095 - val_mae: 0.0601\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.0052 - mae: 0.0462 - val_loss: 0.0087 - val_mae: 0.0553\n",
      "Epoch 1/20\n",
      "138/138 [==============================] - 3s 23ms/step - loss: 0.0063 - mae: 0.0495 - val_loss: 0.0129 - val_mae: 0.0624\n",
      "Epoch 2/20\n",
      "138/138 [==============================] - 3s 22ms/step - loss: 0.0061 - mae: 0.0485 - val_loss: 0.0117 - val_mae: 0.0558\n",
      "Epoch 3/20\n",
      "138/138 [==============================] - 3s 22ms/step - loss: 0.0058 - mae: 0.0472 - val_loss: 0.0123 - val_mae: 0.0564\n",
      "Epoch 4/20\n",
      "138/138 [==============================] - 3s 22ms/step - loss: 0.0057 - mae: 0.0471 - val_loss: 0.0129 - val_mae: 0.0606\n",
      "Epoch 5/20\n",
      "138/138 [==============================] - 3s 21ms/step - loss: 0.0056 - mae: 0.0465 - val_loss: 0.0124 - val_mae: 0.0589\n",
      "Epoch 6/20\n",
      "138/138 [==============================] - 3s 21ms/step - loss: 0.0055 - mae: 0.0458 - val_loss: 0.0112 - val_mae: 0.0581\n",
      "Epoch 7/20\n",
      "138/138 [==============================] - 3s 21ms/step - loss: 0.0054 - mae: 0.0459 - val_loss: 0.0114 - val_mae: 0.0567\n",
      "Epoch 8/20\n",
      "138/138 [==============================] - 3s 22ms/step - loss: 0.0053 - mae: 0.0455 - val_loss: 0.0127 - val_mae: 0.0601\n",
      "Epoch 9/20\n",
      "138/138 [==============================] - 3s 22ms/step - loss: 0.0053 - mae: 0.0453 - val_loss: 0.0119 - val_mae: 0.0577\n",
      "Epoch 10/20\n",
      "138/138 [==============================] - 3s 21ms/step - loss: 0.0052 - mae: 0.0450 - val_loss: 0.0116 - val_mae: 0.0598\n",
      "Epoch 11/20\n",
      "138/138 [==============================] - 3s 21ms/step - loss: 0.0051 - mae: 0.0444 - val_loss: 0.0112 - val_mae: 0.0553\n",
      "Epoch 1/20\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 0.0067 - mae: 0.0487 - val_loss: 0.0080 - val_mae: 0.0570\n",
      "Epoch 2/20\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 0.0064 - mae: 0.0477 - val_loss: 0.0077 - val_mae: 0.0559\n",
      "Epoch 3/20\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 0.0063 - mae: 0.0474 - val_loss: 0.0074 - val_mae: 0.0525\n",
      "Epoch 4/20\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 0.0061 - mae: 0.0466 - val_loss: 0.0073 - val_mae: 0.0533\n",
      "Epoch 5/20\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 0.0060 - mae: 0.0460 - val_loss: 0.0074 - val_mae: 0.0527\n",
      "Epoch 6/20\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 0.0059 - mae: 0.0459 - val_loss: 0.0078 - val_mae: 0.0554\n",
      "Epoch 7/20\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 0.0058 - mae: 0.0454 - val_loss: 0.0080 - val_mae: 0.0557\n",
      "Epoch 8/20\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 0.0057 - mae: 0.0453 - val_loss: 0.0079 - val_mae: 0.0546\n",
      "Epoch 9/20\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 0.0056 - mae: 0.0451 - val_loss: 0.0078 - val_mae: 0.0550\n",
      "Epoch 1/20\n",
      "229/229 [==============================] - 5s 21ms/step - loss: 0.0063 - mae: 0.0480 - val_loss: 0.0059 - val_mae: 0.0520\n",
      "Epoch 2/20\n",
      "229/229 [==============================] - 5s 20ms/step - loss: 0.0062 - mae: 0.0473 - val_loss: 0.0052 - val_mae: 0.0482\n",
      "Epoch 3/20\n",
      "229/229 [==============================] - 5s 20ms/step - loss: 0.0060 - mae: 0.0465 - val_loss: 0.0061 - val_mae: 0.0505\n",
      "Epoch 4/20\n",
      "229/229 [==============================] - 5s 21ms/step - loss: 0.0060 - mae: 0.0465 - val_loss: 0.0061 - val_mae: 0.0544\n",
      "Epoch 5/20\n",
      "229/229 [==============================] - 5s 20ms/step - loss: 0.0058 - mae: 0.0460 - val_loss: 0.0058 - val_mae: 0.0503\n",
      "Epoch 6/20\n",
      "229/229 [==============================] - 5s 21ms/step - loss: 0.0058 - mae: 0.0458 - val_loss: 0.0054 - val_mae: 0.0480\n",
      "Epoch 7/20\n",
      "229/229 [==============================] - 5s 20ms/step - loss: 0.0056 - mae: 0.0451 - val_loss: 0.0053 - val_mae: 0.0486\n",
      "Dataset: New_York_pollution_data.csv\n",
      "Epoch 1/20\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0107 - mae: 0.0605 - val_loss: 0.0055 - val_mae: 0.0508\n",
      "Epoch 2/20\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0075 - mae: 0.0503 - val_loss: 0.0048 - val_mae: 0.0434\n",
      "Epoch 3/20\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0071 - mae: 0.0480 - val_loss: 0.0056 - val_mae: 0.0473\n",
      "Epoch 4/20\n",
      "47/47 [==============================] - 1s 26ms/step - loss: 0.0066 - mae: 0.0465 - val_loss: 0.0055 - val_mae: 0.0455\n",
      "Epoch 5/20\n",
      "47/47 [==============================] - 1s 26ms/step - loss: 0.0064 - mae: 0.0457 - val_loss: 0.0051 - val_mae: 0.0402\n",
      "Epoch 6/20\n",
      "47/47 [==============================] - 1s 26ms/step - loss: 0.0063 - mae: 0.0456 - val_loss: 0.0044 - val_mae: 0.0373\n",
      "Epoch 7/20\n",
      "47/47 [==============================] - 1s 28ms/step - loss: 0.0060 - mae: 0.0438 - val_loss: 0.0048 - val_mae: 0.0411\n",
      "Epoch 8/20\n",
      "47/47 [==============================] - 1s 27ms/step - loss: 0.0056 - mae: 0.0426 - val_loss: 0.0047 - val_mae: 0.0383\n",
      "Epoch 9/20\n",
      "47/47 [==============================] - 1s 26ms/step - loss: 0.0058 - mae: 0.0435 - val_loss: 0.0045 - val_mae: 0.0380\n",
      "Epoch 10/20\n",
      "47/47 [==============================] - 1s 26ms/step - loss: 0.0055 - mae: 0.0430 - val_loss: 0.0047 - val_mae: 0.0390\n",
      "Epoch 11/20\n",
      "47/47 [==============================] - 1s 25ms/step - loss: 0.0053 - mae: 0.0423 - val_loss: 0.0048 - val_mae: 0.0421\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0051 - mae: 0.0398 - val_loss: 0.0077 - val_mae: 0.0476\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.0049 - mae: 0.0390 - val_loss: 0.0071 - val_mae: 0.0434\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.0047 - mae: 0.0380 - val_loss: 0.0072 - val_mae: 0.0435\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.0046 - mae: 0.0377 - val_loss: 0.0072 - val_mae: 0.0457\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.0045 - mae: 0.0376 - val_loss: 0.0075 - val_mae: 0.0466\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.0045 - mae: 0.0372 - val_loss: 0.0070 - val_mae: 0.0438\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 2s 22ms/step - loss: 0.0043 - mae: 0.0363 - val_loss: 0.0072 - val_mae: 0.0453\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.0042 - mae: 0.0362 - val_loss: 0.0072 - val_mae: 0.0447\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.0042 - mae: 0.0361 - val_loss: 0.0071 - val_mae: 0.0430\n",
      "Epoch 10/20\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.0041 - mae: 0.0358 - val_loss: 0.0075 - val_mae: 0.0470\n",
      "Epoch 11/20\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.0040 - mae: 0.0355 - val_loss: 0.0071 - val_mae: 0.0440\n",
      "Epoch 1/20\n",
      "138/138 [==============================] - 3s 21ms/step - loss: 0.0051 - mae: 0.0388 - val_loss: 0.0063 - val_mae: 0.0390\n",
      "Epoch 2/20\n",
      "138/138 [==============================] - 3s 22ms/step - loss: 0.0048 - mae: 0.0375 - val_loss: 0.0057 - val_mae: 0.0362\n",
      "Epoch 3/20\n",
      "138/138 [==============================] - 3s 22ms/step - loss: 0.0046 - mae: 0.0372 - val_loss: 0.0056 - val_mae: 0.0365\n",
      "Epoch 4/20\n",
      "138/138 [==============================] - 3s 22ms/step - loss: 0.0045 - mae: 0.0369 - val_loss: 0.0056 - val_mae: 0.0370\n",
      "Epoch 5/20\n",
      "138/138 [==============================] - 3s 22ms/step - loss: 0.0044 - mae: 0.0365 - val_loss: 0.0058 - val_mae: 0.0367\n",
      "Epoch 6/20\n",
      "138/138 [==============================] - 3s 22ms/step - loss: 0.0044 - mae: 0.0363 - val_loss: 0.0058 - val_mae: 0.0381\n",
      "Epoch 7/20\n",
      "138/138 [==============================] - 3s 24ms/step - loss: 0.0043 - mae: 0.0359 - val_loss: 0.0058 - val_mae: 0.0379\n",
      "Epoch 8/20\n",
      "138/138 [==============================] - 3s 20ms/step - loss: 0.0042 - mae: 0.0356 - val_loss: 0.0059 - val_mae: 0.0393\n",
      "Epoch 1/20\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 0.0048 - mae: 0.0370 - val_loss: 0.0063 - val_mae: 0.0430\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 0.0046 - mae: 0.0363 - val_loss: 0.0063 - val_mae: 0.0439\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 4s 21ms/step - loss: 0.0045 - mae: 0.0358 - val_loss: 0.0065 - val_mae: 0.0434\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 4s 21ms/step - loss: 0.0045 - mae: 0.0358 - val_loss: 0.0062 - val_mae: 0.0439\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 4s 19ms/step - loss: 0.0043 - mae: 0.0352 - val_loss: 0.0059 - val_mae: 0.0421\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 4s 20ms/step - loss: 0.0043 - mae: 0.0351 - val_loss: 0.0062 - val_mae: 0.0427\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 0.0042 - mae: 0.0349 - val_loss: 0.0065 - val_mae: 0.0428\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 4s 21ms/step - loss: 0.0041 - mae: 0.0345 - val_loss: 0.0059 - val_mae: 0.0408\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 0.0041 - mae: 0.0345 - val_loss: 0.0061 - val_mae: 0.0411\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 0.0040 - mae: 0.0339 - val_loss: 0.0060 - val_mae: 0.0417\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 0.0039 - mae: 0.0340 - val_loss: 0.0066 - val_mae: 0.0439\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 4s 22ms/step - loss: 0.0039 - mae: 0.0338 - val_loss: 0.0066 - val_mae: 0.0426\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 5s 30ms/step - loss: 0.0039 - mae: 0.0335 - val_loss: 0.0061 - val_mae: 0.0410\n",
      "Epoch 1/20\n",
      "230/230 [==============================] - 10s 42ms/step - loss: 0.0044 - mae: 0.0359 - val_loss: 0.0111 - val_mae: 0.0538\n",
      "Epoch 2/20\n",
      "230/230 [==============================] - 9s 38ms/step - loss: 0.0043 - mae: 0.0351 - val_loss: 0.0124 - val_mae: 0.0565\n",
      "Epoch 3/20\n",
      "230/230 [==============================] - 9s 38ms/step - loss: 0.0042 - mae: 0.0352 - val_loss: 0.0109 - val_mae: 0.0535\n",
      "Epoch 4/20\n",
      "230/230 [==============================] - 9s 39ms/step - loss: 0.0041 - mae: 0.0347 - val_loss: 0.0121 - val_mae: 0.0559\n",
      "Epoch 5/20\n",
      "230/230 [==============================] - 9s 39ms/step - loss: 0.0041 - mae: 0.0346 - val_loss: 0.0112 - val_mae: 0.0545\n",
      "Epoch 6/20\n",
      "230/230 [==============================] - 9s 39ms/step - loss: 0.0040 - mae: 0.0345 - val_loss: 0.0113 - val_mae: 0.0536\n",
      "Epoch 7/20\n",
      "230/230 [==============================] - 9s 41ms/step - loss: 0.0039 - mae: 0.0341 - val_loss: 0.0122 - val_mae: 0.0573\n",
      "Epoch 8/20\n",
      "230/230 [==============================] - 9s 39ms/step - loss: 0.0038 - mae: 0.0337 - val_loss: 0.0112 - val_mae: 0.0534\n",
      "Dataset: Paris_pollution_data.csv\n",
      "Epoch 1/20\n",
      "47/47 [==============================] - 2s 50ms/step - loss: 0.0090 - mae: 0.0521 - val_loss: 0.0063 - val_mae: 0.0405\n",
      "Epoch 2/20\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 0.0064 - mae: 0.0435 - val_loss: 0.0056 - val_mae: 0.0391\n",
      "Epoch 3/20\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 0.0058 - mae: 0.0418 - val_loss: 0.0051 - val_mae: 0.0386\n",
      "Epoch 4/20\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 0.0053 - mae: 0.0403 - val_loss: 0.0050 - val_mae: 0.0367\n",
      "Epoch 5/20\n",
      "47/47 [==============================] - 2s 50ms/step - loss: 0.0055 - mae: 0.0403 - val_loss: 0.0058 - val_mae: 0.0396\n",
      "Epoch 6/20\n",
      "47/47 [==============================] - 2s 50ms/step - loss: 0.0049 - mae: 0.0391 - val_loss: 0.0055 - val_mae: 0.0380\n",
      "Epoch 7/20\n",
      "47/47 [==============================] - 2s 49ms/step - loss: 0.0045 - mae: 0.0368 - val_loss: 0.0053 - val_mae: 0.0387\n",
      "Epoch 8/20\n",
      "47/47 [==============================] - 2s 48ms/step - loss: 0.0044 - mae: 0.0366 - val_loss: 0.0058 - val_mae: 0.0425\n",
      "Epoch 9/20\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 0.0045 - mae: 0.0379 - val_loss: 0.0056 - val_mae: 0.0423\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 5s 54ms/step - loss: 0.0051 - mae: 0.0374 - val_loss: 0.0034 - val_mae: 0.0306\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.0046 - mae: 0.0346 - val_loss: 0.0032 - val_mae: 0.0281\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 4s 38ms/step - loss: 0.0044 - mae: 0.0340 - val_loss: 0.0032 - val_mae: 0.0263\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 0.0043 - mae: 0.0345 - val_loss: 0.0033 - val_mae: 0.0266\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.0041 - mae: 0.0331 - val_loss: 0.0035 - val_mae: 0.0277\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.0041 - mae: 0.0332 - val_loss: 0.0035 - val_mae: 0.0286\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 4s 41ms/step - loss: 0.0039 - mae: 0.0325 - val_loss: 0.0035 - val_mae: 0.0284\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 4s 42ms/step - loss: 0.0039 - mae: 0.0330 - val_loss: 0.0037 - val_mae: 0.0292\n",
      "Epoch 1/20\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.0038 - mae: 0.0305 - val_loss: 0.0030 - val_mae: 0.0236\n",
      "Epoch 2/20\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0037 - mae: 0.0302 - val_loss: 0.0033 - val_mae: 0.0276\n",
      "Epoch 3/20\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0037 - mae: 0.0299 - val_loss: 0.0033 - val_mae: 0.0261\n",
      "Epoch 4/20\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0035 - mae: 0.0292 - val_loss: 0.0029 - val_mae: 0.0239\n",
      "Epoch 5/20\n",
      "138/138 [==============================] - 6s 40ms/step - loss: 0.0035 - mae: 0.0288 - val_loss: 0.0029 - val_mae: 0.0230\n",
      "Epoch 6/20\n",
      "138/138 [==============================] - 5s 39ms/step - loss: 0.0034 - mae: 0.0287 - val_loss: 0.0028 - val_mae: 0.0233\n",
      "Epoch 7/20\n",
      "138/138 [==============================] - 5s 39ms/step - loss: 0.0034 - mae: 0.0289 - val_loss: 0.0029 - val_mae: 0.0246\n",
      "Epoch 8/20\n",
      "138/138 [==============================] - 5s 39ms/step - loss: 0.0033 - mae: 0.0283 - val_loss: 0.0036 - val_mae: 0.0306\n",
      "Epoch 9/20\n",
      "138/138 [==============================] - 5s 38ms/step - loss: 0.0033 - mae: 0.0284 - val_loss: 0.0030 - val_mae: 0.0248\n",
      "Epoch 10/20\n",
      "138/138 [==============================] - 3s 25ms/step - loss: 0.0033 - mae: 0.0278 - val_loss: 0.0030 - val_mae: 0.0236\n",
      "Epoch 11/20\n",
      "138/138 [==============================] - 3s 24ms/step - loss: 0.0032 - mae: 0.0278 - val_loss: 0.0030 - val_mae: 0.0242\n",
      "Epoch 1/20\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 0.0033 - mae: 0.0277 - val_loss: 0.0072 - val_mae: 0.0409\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 0.0032 - mae: 0.0274 - val_loss: 0.0066 - val_mae: 0.0404\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 4s 23ms/step - loss: 0.0032 - mae: 0.0274 - val_loss: 0.0066 - val_mae: 0.0401\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 4s 23ms/step - loss: 0.0031 - mae: 0.0269 - val_loss: 0.0061 - val_mae: 0.0382\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 0.0031 - mae: 0.0267 - val_loss: 0.0067 - val_mae: 0.0402\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 4s 23ms/step - loss: 0.0030 - mae: 0.0264 - val_loss: 0.0069 - val_mae: 0.0409\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 0.0030 - mae: 0.0264 - val_loss: 0.0069 - val_mae: 0.0397\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 4s 23ms/step - loss: 0.0030 - mae: 0.0264 - val_loss: 0.0064 - val_mae: 0.0409\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 4s 23ms/step - loss: 0.0030 - mae: 0.0267 - val_loss: 0.0067 - val_mae: 0.0397\n",
      "Epoch 1/20\n",
      "230/230 [==============================] - 5s 24ms/step - loss: 0.0038 - mae: 0.0297 - val_loss: 0.0053 - val_mae: 0.0336\n",
      "Epoch 2/20\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 0.0036 - mae: 0.0290 - val_loss: 0.0047 - val_mae: 0.0306\n",
      "Epoch 3/20\n",
      "230/230 [==============================] - 5s 24ms/step - loss: 0.0034 - mae: 0.0281 - val_loss: 0.0049 - val_mae: 0.0349\n",
      "Epoch 4/20\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 0.0033 - mae: 0.0278 - val_loss: 0.0048 - val_mae: 0.0321\n",
      "Epoch 5/20\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 0.0033 - mae: 0.0280 - val_loss: 0.0049 - val_mae: 0.0328\n",
      "Epoch 6/20\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 0.0033 - mae: 0.0280 - val_loss: 0.0053 - val_mae: 0.0354\n",
      "Epoch 7/20\n",
      "230/230 [==============================] - 5s 23ms/step - loss: 0.0032 - mae: 0.0275 - val_loss: 0.0047 - val_mae: 0.0320\n",
      "Dataset: Seoul_pollution_data.csv\n",
      "Epoch 1/20\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.0125 - mae: 0.0749 - val_loss: 0.0123 - val_mae: 0.0732\n",
      "Epoch 2/20\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 0.0085 - mae: 0.0619 - val_loss: 0.0107 - val_mae: 0.0657\n",
      "Epoch 3/20\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 0.0074 - mae: 0.0574 - val_loss: 0.0107 - val_mae: 0.0656\n",
      "Epoch 4/20\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.0068 - mae: 0.0544 - val_loss: 0.0117 - val_mae: 0.0695\n",
      "Epoch 5/20\n",
      "46/46 [==============================] - 1s 30ms/step - loss: 0.0064 - mae: 0.0537 - val_loss: 0.0116 - val_mae: 0.0655\n",
      "Epoch 6/20\n",
      "46/46 [==============================] - 1s 27ms/step - loss: 0.0060 - mae: 0.0519 - val_loss: 0.0122 - val_mae: 0.0673\n",
      "Epoch 7/20\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.0055 - mae: 0.0498 - val_loss: 0.0129 - val_mae: 0.0679\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0080 - mae: 0.0578 - val_loss: 0.0084 - val_mae: 0.0534\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.0071 - mae: 0.0540 - val_loss: 0.0075 - val_mae: 0.0513\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 2s 27ms/step - loss: 0.0068 - mae: 0.0532 - val_loss: 0.0073 - val_mae: 0.0486\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0063 - mae: 0.0512 - val_loss: 0.0071 - val_mae: 0.0484\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0060 - mae: 0.0499 - val_loss: 0.0072 - val_mae: 0.0508\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.0057 - mae: 0.0488 - val_loss: 0.0076 - val_mae: 0.0496\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.0056 - mae: 0.0483 - val_loss: 0.0069 - val_mae: 0.0484\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0055 - mae: 0.0481 - val_loss: 0.0076 - val_mae: 0.0503\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.0053 - mae: 0.0471 - val_loss: 0.0074 - val_mae: 0.0500\n",
      "Epoch 10/20\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.0051 - mae: 0.0467 - val_loss: 0.0073 - val_mae: 0.0502\n",
      "Epoch 11/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0049 - mae: 0.0453 - val_loss: 0.0075 - val_mae: 0.0513\n",
      "Epoch 12/20\n",
      "92/92 [==============================] - 2s 26ms/step - loss: 0.0048 - mae: 0.0452 - val_loss: 0.0078 - val_mae: 0.0526\n",
      "Epoch 1/20\n",
      "137/137 [==============================] - 3s 24ms/step - loss: 0.0059 - mae: 0.0484 - val_loss: 0.0059 - val_mae: 0.0431\n",
      "Epoch 2/20\n",
      "137/137 [==============================] - 3s 23ms/step - loss: 0.0055 - mae: 0.0465 - val_loss: 0.0057 - val_mae: 0.0422\n",
      "Epoch 3/20\n",
      "137/137 [==============================] - 3s 24ms/step - loss: 0.0053 - mae: 0.0455 - val_loss: 0.0058 - val_mae: 0.0425\n",
      "Epoch 4/20\n",
      "137/137 [==============================] - 3s 22ms/step - loss: 0.0051 - mae: 0.0451 - val_loss: 0.0060 - val_mae: 0.0441\n",
      "Epoch 5/20\n",
      "137/137 [==============================] - 3s 23ms/step - loss: 0.0050 - mae: 0.0444 - val_loss: 0.0060 - val_mae: 0.0428\n",
      "Epoch 6/20\n",
      "137/137 [==============================] - 3s 23ms/step - loss: 0.0049 - mae: 0.0441 - val_loss: 0.0064 - val_mae: 0.0450\n",
      "Epoch 7/20\n",
      "137/137 [==============================] - 3s 23ms/step - loss: 0.0049 - mae: 0.0443 - val_loss: 0.0063 - val_mae: 0.0445\n",
      "Epoch 1/20\n",
      "183/183 [==============================] - 5s 25ms/step - loss: 0.0054 - mae: 0.0448 - val_loss: 0.0083 - val_mae: 0.0530\n",
      "Epoch 2/20\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0053 - mae: 0.0442 - val_loss: 0.0080 - val_mae: 0.0523\n",
      "Epoch 3/20\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0051 - mae: 0.0437 - val_loss: 0.0084 - val_mae: 0.0546\n",
      "Epoch 4/20\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 0.0050 - mae: 0.0433 - val_loss: 0.0084 - val_mae: 0.0542\n",
      "Epoch 5/20\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0050 - mae: 0.0430 - val_loss: 0.0084 - val_mae: 0.0547\n",
      "Epoch 6/20\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 0.0048 - mae: 0.0423 - val_loss: 0.0085 - val_mae: 0.0542\n",
      "Epoch 7/20\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0047 - mae: 0.0419 - val_loss: 0.0083 - val_mae: 0.0532\n",
      "Epoch 1/20\n",
      "228/228 [==============================] - 5s 23ms/step - loss: 0.0057 - mae: 0.0454 - val_loss: 0.0094 - val_mae: 0.0578\n",
      "Epoch 2/20\n",
      "228/228 [==============================] - 5s 22ms/step - loss: 0.0055 - mae: 0.0447 - val_loss: 0.0092 - val_mae: 0.0559\n",
      "Epoch 3/20\n",
      "228/228 [==============================] - 5s 21ms/step - loss: 0.0053 - mae: 0.0443 - val_loss: 0.0094 - val_mae: 0.0565\n",
      "Epoch 4/20\n",
      "228/228 [==============================] - 5s 23ms/step - loss: 0.0052 - mae: 0.0437 - val_loss: 0.0100 - val_mae: 0.0600\n",
      "Epoch 5/20\n",
      "228/228 [==============================] - 5s 23ms/step - loss: 0.0052 - mae: 0.0438 - val_loss: 0.0101 - val_mae: 0.0603\n",
      "Epoch 6/20\n",
      "228/228 [==============================] - 5s 21ms/step - loss: 0.0051 - mae: 0.0434 - val_loss: 0.0099 - val_mae: 0.0584\n",
      "Epoch 7/20\n",
      "228/228 [==============================] - 5s 22ms/step - loss: 0.0049 - mae: 0.0425 - val_loss: 0.0096 - val_mae: 0.0584\n",
      "Dataset: Shanghai_pollution_data.csv\n",
      "Epoch 1/20\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 0.0067 - mae: 0.0503 - val_loss: 0.0039 - val_mae: 0.0346\n",
      "Epoch 2/20\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 0.0036 - mae: 0.0366 - val_loss: 0.0036 - val_mae: 0.0324\n",
      "Epoch 3/20\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.0033 - mae: 0.0349 - val_loss: 0.0035 - val_mae: 0.0317\n",
      "Epoch 4/20\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.0030 - mae: 0.0333 - val_loss: 0.0035 - val_mae: 0.0314\n",
      "Epoch 5/20\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.0029 - mae: 0.0321 - val_loss: 0.0035 - val_mae: 0.0319\n",
      "Epoch 6/20\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 0.0028 - mae: 0.0320 - val_loss: 0.0036 - val_mae: 0.0329\n",
      "Epoch 7/20\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 0.0027 - mae: 0.0314 - val_loss: 0.0035 - val_mae: 0.0315\n",
      "Epoch 8/20\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 0.0026 - mae: 0.0307 - val_loss: 0.0035 - val_mae: 0.0319\n",
      "Epoch 9/20\n",
      "46/46 [==============================] - 1s 27ms/step - loss: 0.0025 - mae: 0.0301 - val_loss: 0.0034 - val_mae: 0.0320\n",
      "Epoch 10/20\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 0.0024 - mae: 0.0297 - val_loss: 0.0035 - val_mae: 0.0306\n",
      "Epoch 11/20\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.0024 - mae: 0.0292 - val_loss: 0.0034 - val_mae: 0.0302\n",
      "Epoch 12/20\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.0023 - mae: 0.0286 - val_loss: 0.0034 - val_mae: 0.0305\n",
      "Epoch 13/20\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.0022 - mae: 0.0287 - val_loss: 0.0036 - val_mae: 0.0316\n",
      "Epoch 14/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.0022 - mae: 0.0284 - val_loss: 0.0034 - val_mae: 0.0312\n",
      "Epoch 15/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.0022 - mae: 0.0281 - val_loss: 0.0035 - val_mae: 0.0312\n",
      "Epoch 16/20\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.0021 - mae: 0.0278 - val_loss: 0.0034 - val_mae: 0.0312\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0028 - mae: 0.0302 - val_loss: 0.0046 - val_mae: 0.0356\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 1s 15ms/step - loss: 0.0026 - mae: 0.0290 - val_loss: 0.0044 - val_mae: 0.0335\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 1s 14ms/step - loss: 0.0025 - mae: 0.0287 - val_loss: 0.0044 - val_mae: 0.0333\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0025 - mae: 0.0279 - val_loss: 0.0042 - val_mae: 0.0330\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 1s 15ms/step - loss: 0.0024 - mae: 0.0279 - val_loss: 0.0043 - val_mae: 0.0322\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 1s 15ms/step - loss: 0.0024 - mae: 0.0277 - val_loss: 0.0044 - val_mae: 0.0350\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0023 - mae: 0.0275 - val_loss: 0.0047 - val_mae: 0.0349\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0023 - mae: 0.0273 - val_loss: 0.0044 - val_mae: 0.0335\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0022 - mae: 0.0269 - val_loss: 0.0048 - val_mae: 0.0366\n",
      "Epoch 1/20\n",
      "137/137 [==============================] - 3s 20ms/step - loss: 0.0031 - mae: 0.0299 - val_loss: 0.0039 - val_mae: 0.0301\n",
      "Epoch 2/20\n",
      "137/137 [==============================] - 3s 21ms/step - loss: 0.0029 - mae: 0.0294 - val_loss: 0.0039 - val_mae: 0.0291\n",
      "Epoch 3/20\n",
      "137/137 [==============================] - 3s 20ms/step - loss: 0.0028 - mae: 0.0287 - val_loss: 0.0039 - val_mae: 0.0288\n",
      "Epoch 4/20\n",
      "137/137 [==============================] - 3s 20ms/step - loss: 0.0028 - mae: 0.0286 - val_loss: 0.0045 - val_mae: 0.0309\n",
      "Epoch 5/20\n",
      "137/137 [==============================] - 3s 19ms/step - loss: 0.0027 - mae: 0.0281 - val_loss: 0.0041 - val_mae: 0.0291\n",
      "Epoch 6/20\n",
      "137/137 [==============================] - 3s 19ms/step - loss: 0.0026 - mae: 0.0278 - val_loss: 0.0041 - val_mae: 0.0320\n",
      "Epoch 7/20\n",
      "137/137 [==============================] - 3s 18ms/step - loss: 0.0026 - mae: 0.0277 - val_loss: 0.0043 - val_mae: 0.0334\n",
      "Epoch 1/20\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0031 - mae: 0.0291 - val_loss: 0.0041 - val_mae: 0.0348\n",
      "Epoch 2/20\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0030 - mae: 0.0291 - val_loss: 0.0042 - val_mae: 0.0353\n",
      "Epoch 3/20\n",
      "183/183 [==============================] - 3s 17ms/step - loss: 0.0029 - mae: 0.0286 - val_loss: 0.0041 - val_mae: 0.0337\n",
      "Epoch 4/20\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0029 - mae: 0.0283 - val_loss: 0.0042 - val_mae: 0.0345\n",
      "Epoch 5/20\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0028 - mae: 0.0279 - val_loss: 0.0045 - val_mae: 0.0350\n",
      "Epoch 6/20\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.0027 - mae: 0.0277 - val_loss: 0.0045 - val_mae: 0.0366\n",
      "Epoch 1/20\n",
      "228/228 [==============================] - 4s 16ms/step - loss: 0.0032 - mae: 0.0301 - val_loss: 0.0041 - val_mae: 0.0375\n",
      "Epoch 2/20\n",
      "228/228 [==============================] - 3s 15ms/step - loss: 0.0031 - mae: 0.0294 - val_loss: 0.0047 - val_mae: 0.0382\n",
      "Epoch 3/20\n",
      "228/228 [==============================] - 3s 15ms/step - loss: 0.0030 - mae: 0.0292 - val_loss: 0.0046 - val_mae: 0.0379\n",
      "Epoch 4/20\n",
      "228/228 [==============================] - 3s 15ms/step - loss: 0.0030 - mae: 0.0291 - val_loss: 0.0043 - val_mae: 0.0395\n",
      "Epoch 5/20\n",
      "228/228 [==============================] - 3s 15ms/step - loss: 0.0029 - mae: 0.0287 - val_loss: 0.0046 - val_mae: 0.0409\n",
      "Epoch 6/20\n",
      "228/228 [==============================] - 3s 15ms/step - loss: 0.0028 - mae: 0.0284 - val_loss: 0.0047 - val_mae: 0.0400\n",
      "Dataset: Tokyo_pollution_data.csv\n",
      "Epoch 1/20\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.0100 - mae: 0.0607 - val_loss: 0.0078 - val_mae: 0.0586\n",
      "Epoch 2/20\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.0058 - mae: 0.0474 - val_loss: 0.0074 - val_mae: 0.0532\n",
      "Epoch 3/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.0050 - mae: 0.0446 - val_loss: 0.0070 - val_mae: 0.0508\n",
      "Epoch 4/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.0046 - mae: 0.0428 - val_loss: 0.0074 - val_mae: 0.0513\n",
      "Epoch 5/20\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.0043 - mae: 0.0416 - val_loss: 0.0072 - val_mae: 0.0512\n",
      "Epoch 6/20\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.0041 - mae: 0.0406 - val_loss: 0.0077 - val_mae: 0.0527\n",
      "Epoch 7/20\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.0039 - mae: 0.0394 - val_loss: 0.0075 - val_mae: 0.0523\n",
      "Epoch 8/20\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.0037 - mae: 0.0392 - val_loss: 0.0076 - val_mae: 0.0516\n",
      "Epoch 1/20\n",
      "91/91 [==============================] - 1s 16ms/step - loss: 0.0054 - mae: 0.0455 - val_loss: 0.0080 - val_mae: 0.0513\n",
      "Epoch 2/20\n",
      "91/91 [==============================] - 1s 16ms/step - loss: 0.0050 - mae: 0.0434 - val_loss: 0.0076 - val_mae: 0.0498\n",
      "Epoch 3/20\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.0046 - mae: 0.0418 - val_loss: 0.0075 - val_mae: 0.0493\n",
      "Epoch 4/20\n",
      "91/91 [==============================] - 1s 16ms/step - loss: 0.0045 - mae: 0.0413 - val_loss: 0.0079 - val_mae: 0.0504\n",
      "Epoch 5/20\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.0043 - mae: 0.0405 - val_loss: 0.0081 - val_mae: 0.0511\n",
      "Epoch 6/20\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.0042 - mae: 0.0400 - val_loss: 0.0079 - val_mae: 0.0497\n",
      "Epoch 7/20\n",
      "91/91 [==============================] - 1s 16ms/step - loss: 0.0041 - mae: 0.0394 - val_loss: 0.0091 - val_mae: 0.0533\n",
      "Epoch 8/20\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.0039 - mae: 0.0389 - val_loss: 0.0090 - val_mae: 0.0524\n",
      "Epoch 1/20\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.0054 - mae: 0.0435 - val_loss: 0.0070 - val_mae: 0.0443\n",
      "Epoch 2/20\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.0050 - mae: 0.0422 - val_loss: 0.0053 - val_mae: 0.0371\n",
      "Epoch 3/20\n",
      "137/137 [==============================] - 2s 17ms/step - loss: 0.0048 - mae: 0.0414 - val_loss: 0.0059 - val_mae: 0.0408\n",
      "Epoch 4/20\n",
      "137/137 [==============================] - 2s 18ms/step - loss: 0.0047 - mae: 0.0409 - val_loss: 0.0054 - val_mae: 0.0372\n",
      "Epoch 5/20\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 0.0046 - mae: 0.0404 - val_loss: 0.0059 - val_mae: 0.0412\n",
      "Epoch 6/20\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 0.0044 - mae: 0.0398 - val_loss: 0.0055 - val_mae: 0.0366\n",
      "Epoch 7/20\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.0043 - mae: 0.0393 - val_loss: 0.0057 - val_mae: 0.0381\n",
      "Epoch 1/20\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0049 - mae: 0.0402 - val_loss: 0.0062 - val_mae: 0.0449\n",
      "Epoch 2/20\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0047 - mae: 0.0392 - val_loss: 0.0063 - val_mae: 0.0450\n",
      "Epoch 3/20\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0045 - mae: 0.0385 - val_loss: 0.0066 - val_mae: 0.0464\n",
      "Epoch 4/20\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0045 - mae: 0.0386 - val_loss: 0.0071 - val_mae: 0.0476\n",
      "Epoch 5/20\n",
      "182/182 [==============================] - 3s 16ms/step - loss: 0.0043 - mae: 0.0379 - val_loss: 0.0066 - val_mae: 0.0453\n",
      "Epoch 6/20\n",
      "182/182 [==============================] - 3s 15ms/step - loss: 0.0042 - mae: 0.0376 - val_loss: 0.0068 - val_mae: 0.0464\n",
      "Epoch 1/20\n",
      "228/228 [==============================] - 3s 15ms/step - loss: 0.0050 - mae: 0.0405 - val_loss: 0.0067 - val_mae: 0.0513\n",
      "Epoch 2/20\n",
      "228/228 [==============================] - 3s 15ms/step - loss: 0.0048 - mae: 0.0400 - val_loss: 0.0064 - val_mae: 0.0504\n",
      "Epoch 3/20\n",
      "228/228 [==============================] - 4s 16ms/step - loss: 0.0047 - mae: 0.0394 - val_loss: 0.0062 - val_mae: 0.0510\n",
      "Epoch 4/20\n",
      "228/228 [==============================] - 3s 15ms/step - loss: 0.0046 - mae: 0.0390 - val_loss: 0.0065 - val_mae: 0.0510\n",
      "Epoch 5/20\n",
      "228/228 [==============================] - 3s 15ms/step - loss: 0.0046 - mae: 0.0390 - val_loss: 0.0065 - val_mae: 0.0509\n",
      "Epoch 6/20\n",
      "228/228 [==============================] - 4s 16ms/step - loss: 0.0044 - mae: 0.0382 - val_loss: 0.0065 - val_mae: 0.0518\n",
      "Epoch 7/20\n",
      "228/228 [==============================] - 3s 15ms/step - loss: 0.0043 - mae: 0.0379 - val_loss: 0.0066 - val_mae: 0.0519\n",
      "Epoch 8/20\n",
      "228/228 [==============================] - 3s 15ms/step - loss: 0.0042 - mae: 0.0377 - val_loss: 0.0070 - val_mae: 0.0531\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f'Dataset: {dataset[17:]}')\n",
    "    df = pd.read_csv(dataset)\n",
    "    df = df[features]\n",
    "    data_array = df.to_numpy()\n",
    "    scaler = MinMaxScaler()\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    data_scaled = scaler.fit_transform(data_array)\n",
    "\n",
    "    X, y = create_sequences(data_scaled, WINDOW_SIZE)\n",
    "\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                  epochs=20, batch_size=32, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('./models/mj_fine_tuned_gru_model_capable.keras')\n",
    "model.save('./models/mj_fine_tuned_gru_model_capable.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('./models/mj_fine_tuned_gru_model_capable.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:root:TensorFlow Decision Forests 1.8.1 is compatible with the following TensorFlow Versions: ['2.15.0']. However, TensorFlow 2.15.1 was detected. This can cause issues with the TF API and symbols in the custom C++ ops. See the TF and TF-DF compatibility table at https://github.com/tensorflow/decision-forests/blob/main/documentation/known_issues.md#compatibility-table.\n",
      "WARNING:root:Failure to load the inference.so custom c++ tensorflow ops. This error is likely caused the version of TensorFlow and TensorFlow Decision Forests are not compatible. Full error:C:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\inference.so not found\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\Scripts\\tensorflowjs_converter.exe\\__main__.py\", line 4, in <module>\n",
      "  File \"C:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflowjs\\__init__.py\", line 21, in <module>\n",
      "    from tensorflowjs import converters\n",
      "  File \"C:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflowjs\\converters\\__init__.py\", line 21, in <module>\n",
      "    from tensorflowjs.converters.converter import convert\n",
      "  File \"C:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflowjs\\converters\\converter.py\", line 38, in <module>\n",
      "    from tensorflowjs.converters import tf_saved_model_conversion_v2\n",
      "  File \"C:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflowjs\\converters\\tf_saved_model_conversion_v2.py\", line 28, in <module>\n",
      "    import tensorflow_decision_forests\n",
      "  File \"C:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflow_decision_forests\\__init__.py\", line 64, in <module>\n",
      "    from tensorflow_decision_forests import keras\n",
      "  File \"C:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflow_decision_forests\\keras\\__init__.py\", line 53, in <module>\n",
      "    from tensorflow_decision_forests.keras import core\n",
      "  File \"C:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflow_decision_forests\\keras\\core.py\", line 62, in <module>\n",
      "    from tensorflow_decision_forests.keras import core_inference\n",
      "  File \"C:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflow_decision_forests\\keras\\core_inference.py\", line 36, in <module>\n",
      "    from tensorflow_decision_forests.tensorflow.ops.inference import api as tf_op\n",
      "  File \"C:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\api.py\", line 179, in <module>\n",
      "    from tensorflow_decision_forests.tensorflow.ops.inference import op\n",
      "  File \"C:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\op.py\", line 15, in <module>\n",
      "    from tensorflow_decision_forests.tensorflow.ops.inference.op_dynamic import *\n",
      "  File \"C:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\op_dynamic.py\", line 24, in <module>\n",
      "    raise e\n",
      "  File \"C:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\op_dynamic.py\", line 21, in <module>\n",
      "    ops = tf.load_op_library(resource_loader.get_path_to_datafile(\"inference.so\"))\n",
      "  File \"C:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflow\\python\\framework\\load_library.py\", line 54, in load_op_library\n",
      "    lib_handle = py_tf.TF_LoadLibrary(library_filename)\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: C:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\inference.so not found\n"
     ]
    }
   ],
   "source": [
    "!tensorflowjs_converter --input_format keras ./models/mj_fine_tuned_gru_model.keras ./model/mj_fine_tuned_gru_model_tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:TensorFlow Decision Forests 1.8.1 is compatible with the following TensorFlow Versions: ['2.15.0']. However, TensorFlow 2.15.1 was detected. This can cause issues with the TF API and symbols in the custom C++ ops. See the TF and TF-DF compatibility table at https://github.com/tensorflow/decision-forests/blob/main/documentation/known_issues.md#compatibility-table.\n",
      "WARNING:root:Failure to load the inference.so custom c++ tensorflow ops. This error is likely caused the version of TensorFlow and TensorFlow Decision Forests are not compatible. Full error:c:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\inference.so not found\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "c:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\inference.so not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflowjs\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfjs\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 모델 변환\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflowjs\\__init__.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-imports\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflowjs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m converters\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflowjs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quantization\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflowjs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version\n",
      "File \u001b[1;32mc:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflowjs\\converters\\__init__.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-imports,line-too-long\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflowjs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverters\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflowjs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverters\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras_h5_conversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save_keras_model\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflowjs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverters\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras_tfjs_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deserialize_keras_model\n",
      "File \u001b[1;32mc:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflowjs\\converters\\converter.py:38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflowjs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_h5_conversion \u001b[38;5;28;01mas\u001b[39;00m conversion\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflowjs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tfjs_loader\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflowjs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_saved_model_conversion_v2\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ZipFile, is_zipfile\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdispatch_keras_h5_to_tfjs_layers_model_conversion\u001b[39m(\n\u001b[0;32m     43\u001b[0m     h5_path, output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, quantization_dtype_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     44\u001b[0m     split_weights_by_layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     45\u001b[0m     weight_shard_size_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m     46\u001b[0m     metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflowjs\\converters\\tf_saved_model_conversion_v2.py:28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ZipFile\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Required to load saved models that use TFDF.\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n",
      "File \u001b[1;32mc:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflow_decision_forests\\__init__.py:64\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_version\n\u001b[0;32m     62\u001b[0m check_version\u001b[38;5;241m.\u001b[39mcheck_version(__version__, compatible_tf_versions)\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m py_tree\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m builder\n",
      "File \u001b[1;32mc:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflow_decision_forests\\keras\\__init__.py:53\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Decision Forest in a Keras Model.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mUsage example:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, List\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wrappers\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Utility classes\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflow_decision_forests\\keras\\core.py:62\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inspector \u001b[38;5;28;01mas\u001b[39;00m inspector_lib\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tuner \u001b[38;5;28;01mas\u001b[39;00m tuner_lib\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core_inference\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cc_logging\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core \u001b[38;5;28;01mas\u001b[39;00m tf_core\n",
      "File \u001b[1;32mc:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflow_decision_forests\\keras\\core_inference.py:36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core_inference \u001b[38;5;28;01mas\u001b[39;00m tf_core\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_logging\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api \u001b[38;5;28;01mas\u001b[39;00m tf_op\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myggdrasil_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlearner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m abstract_learner_pb2\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myggdrasil_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlearner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultitasker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multitasker_pb2\n",
      "File \u001b[1;32mc:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\api.py:179\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inspector \u001b[38;5;28;01mas\u001b[39;00m inspector_lib\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf1_compatibility\n\u001b[1;32m--> 179\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m op\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myggdrasil_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_spec_pb2\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myggdrasil_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m abstract_model_pb2\n",
      "File \u001b[1;32mc:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\op.py:15\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2021 Google LLC.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mop_dynamic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\op_dynamic.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     23\u001b[0m   check_version\u001b[38;5;241m.\u001b[39minfo_fail_to_load_custom_op(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minference.so\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Importing all the symbols.\u001b[39;00m\n\u001b[0;32m     27\u001b[0m module \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;18m__name__\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\op_dynamic.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 21\u001b[0m   ops \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_op_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_path_to_datafile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minference.so\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     23\u001b[0m   check_version\u001b[38;5;241m.\u001b[39minfo_fail_to_load_custom_op(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minference.so\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflow\\python\\framework\\load_library.py:54\u001b[0m, in \u001b[0;36mload_op_library\u001b[1;34m(library_filename)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_op_library\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_op_library\u001b[39m(library_filename):\n\u001b[0;32m     33\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a TensorFlow plugin, containing custom ops and kernels.\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m  Pass \"library_filename\" to a platform-specific mechanism for dynamically\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m    RuntimeError: when unable to load the library or get the python wrappers.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m   lib_handle \u001b[38;5;241m=\u001b[39m \u001b[43mpy_tf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_LoadLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlibrary_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m     wrappers \u001b[38;5;241m=\u001b[39m _pywrap_python_op_gen\u001b[38;5;241m.\u001b[39mGetPythonWrappers(\n\u001b[0;32m     57\u001b[0m         py_tf\u001b[38;5;241m.\u001b[39mTF_GetOpList(lib_handle))\n",
      "\u001b[1;31mNotFoundError\u001b[0m: c:\\Users\\minja\\anaconda3\\envs\\tfjs_convert\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\inference.so not found"
     ]
    }
   ],
   "source": [
    "import tensorflowjs as tfjs\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 모델 변환\n",
    "model = load_model('model.h5')\n",
    "tfjs.converters.save_keras_model(model, 'tfjs_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gram_py_3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
